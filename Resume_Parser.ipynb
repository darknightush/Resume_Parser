{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume Parser.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPASOZvRoN17tyihfNW/KSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darknightush/Resume_Parser/blob/Master/Resume_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume Parser"
      ],
      "metadata": {
        "id": "x-vBp4WR5GaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import spacy\n",
        "import pickle\n",
        "import random"
      ],
      "metadata": {
        "id": "Eigq9ZHW5ILC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pickle.load(open('data.pkl','rb'))\n",
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0tH6ayH5NIR",
        "outputId": "f6ee0790-23f3-4945-a4c3-cc33ec594cfc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [(1749, 1755, 'Companies worked at'),\n",
              "   (1696, 1702, 'Companies worked at'),\n",
              "   (1417, 1423, 'Companies worked at'),\n",
              "   (1356, 1793, 'Skills'),\n",
              "   (1209, 1215, 'Companies worked at'),\n",
              "   (1136, 1248, 'Skills'),\n",
              "   (928, 932, 'Graduation Year'),\n",
              "   (858, 889, 'College Name'),\n",
              "   (821, 856, 'Degree'),\n",
              "   (787, 791, 'Graduation Year'),\n",
              "   (744, 750, 'Companies worked at'),\n",
              "   (722, 742, 'Designation'),\n",
              "   (658, 664, 'Companies worked at'),\n",
              "   (640, 656, 'Designation'),\n",
              "   (574, 580, 'Companies worked at'),\n",
              "   (555, 573, 'Designation'),\n",
              "   (470, 493, 'Companies worked at'),\n",
              "   (444, 469, 'Designation'),\n",
              "   (308, 314, 'Companies worked at'),\n",
              "   (234, 240, 'Companies worked at'),\n",
              "   (175, 198, 'Companies worked at'),\n",
              "   (93, 137, 'Email Address'),\n",
              "   (39, 48, 'Location'),\n",
              "   (13, 38, 'Designation'),\n",
              "   (0, 12, 'Name')]})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Blank Model\n",
        "nlp = spacy.blank('en')\n",
        "\n",
        "def training(data):\n",
        "    # Remove all pipelines and add NER pipeline from the model\n",
        "    if 'ner'not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        # adding NER pipeline to nlp model\n",
        "        nlp.add_pipe(ner,last=True)\n",
        "    \n",
        "    #Add labels in the NLP pipeline\n",
        "    for _, annotation in data:\n",
        "        for ent in annotation.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "    \n",
        "    #Remove other pipelines if they are there\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(30): # train for 10 iterations\n",
        "            print(\"Starting iteration \" + str(itn))\n",
        "            random.shuffle(data)\n",
        "            losses = {}\n",
        "            index = 0\n",
        "            for text, annotations in data:\n",
        "                try:\n",
        "                    nlp.update(\n",
        "                        [text],  # batch of texts\n",
        "                        [annotations],  # batch of annotations\n",
        "                        drop=0.2,  # dropout - make it harder to memorise data\n",
        "                        sgd=optimizer,  # callable to update weights\n",
        "                        losses=losses)\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "                \n",
        "            print(losses)\n",
        "# Start Training model\n",
        "training(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEKSUpGT5N0B",
        "outputId": "3b77fcfa-c859-478f-ca72-1bd9ed000c02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting iteration 0\n",
            "{'ner': 15231.471876251697}\n",
            "Starting iteration 1\n",
            "{'ner': 10172.174889678263}\n",
            "Starting iteration 2\n",
            "{'ner': 8747.356816184034}\n",
            "Starting iteration 3\n",
            "{'ner': 6749.569263962965}\n",
            "Starting iteration 4\n",
            "{'ner': 6244.544416655366}\n",
            "Starting iteration 5\n",
            "{'ner': 5397.981417064491}\n",
            "Starting iteration 6\n",
            "{'ner': 5446.890278133104}\n",
            "Starting iteration 7\n",
            "{'ner': 5473.634519398004}\n",
            "Starting iteration 8\n",
            "{'ner': 5081.475572136505}\n",
            "Starting iteration 9\n",
            "{'ner': 4303.01603472484}\n",
            "Starting iteration 10\n",
            "{'ner': 4672.850855090795}\n",
            "Starting iteration 11\n",
            "{'ner': 3386.8970842396193}\n",
            "Starting iteration 12\n",
            "{'ner': 4433.490901241592}\n",
            "Starting iteration 13\n",
            "{'ner': 5484.845435524629}\n",
            "Starting iteration 14\n",
            "{'ner': 4369.370967092233}\n",
            "Starting iteration 15\n",
            "{'ner': 5131.341105034062}\n",
            "Starting iteration 16\n",
            "{'ner': 3581.448207004029}\n",
            "Starting iteration 17\n",
            "{'ner': 3352.329272256251}\n",
            "Starting iteration 18\n",
            "{'ner': 2786.8149138532644}\n",
            "Starting iteration 19\n",
            "{'ner': 3215.345655666321}\n",
            "Starting iteration 20\n",
            "{'ner': 3189.3545884744017}\n",
            "Starting iteration 21\n",
            "{'ner': 3093.277315999657}\n",
            "Starting iteration 22\n",
            "{'ner': 2841.81173659128}\n",
            "Starting iteration 23\n",
            "{'ner': 2773.274230459786}\n",
            "Starting iteration 24\n",
            "{'ner': 3625.101360386895}\n",
            "Starting iteration 25\n",
            "{'ner': 3091.22044601208}\n",
            "Starting iteration 26\n",
            "{'ner': 2785.232521007363}\n",
            "Starting iteration 27\n",
            "{'ner': 2097.223358129393}\n",
            "Starting iteration 28\n",
            "{'ner': 2457.872179608017}\n",
            "Starting iteration 29\n",
            "{'ner': 3307.5993963302176}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.to_disk('nlp_ner_model')"
      ],
      "metadata": {
        "id": "zAeQIvRIAhkW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Model\n",
        "nlp_model = spacy.load('nlp_ner_model')"
      ],
      "metadata": {
        "id": "m3zNnkKSAkpc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trying and seeing the prediction of the model\n",
        "doc = nlp_model(data[0][0])\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.label_.upper():{30}}-{ent.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t5PzJMoAkrw",
        "outputId": "993a7808-e85e-494e-cc18-2bb3def05762"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                          -Arpit Jain\n",
            "DESIGNATION                   -Quality Analyst\n",
            "COMPANIES WORKED AT           -ThoughtWorks Technologies\n",
            "EMAIL ADDRESS                 -indeed.com/r/Arpit-Jain/3714fe32f98b03a9\n",
            "DESIGNATION                   -Quality Analyst\n",
            "DESIGNATION                   -Quality Analyst\n",
            "COMPANIES WORKED AT           -ThoughtWorks Technologies\n",
            "COMPANIES WORKED AT           -ThoughtWorks Technologies\n",
            "DESIGNATION                   -Quality Analyst\n",
            "COMPANIES WORKED AT           -ThoughtWorks Technologies\n",
            "DEGREE                        -B.Tech\n",
            "COLLEGE NAME                  -Jaypee Institute Of Information Technology\n",
            "SKILLS                        -SKILLS  Manual Testing, Protractor, Selenium Webdriver, Automation Testing, API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Wmw13aAkvC",
        "outputId": "0213cbf7-8818-4c8f-eb88-a0b85f647167"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.19.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, fitz\n",
        "fname = 'Smith Resume.pdf'\n",
        "doc = fitz.open(fname)\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text = text + str(page.get_text())\n",
        "art = \" \".join(text.split('\\n'))\n",
        "print(art)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-539SE7Akxe",
        "outputId": "b87ef860-86bb-41b5-ac01-35e62f8cdc0f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michael Smith  BI / Big Data/ Azure  Manchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f    10+ years of Experience in Designing, Development, Administration, Analysis,  Management  inthe  Business  Intelligence  Data  warehousing,  Client  Server  Technologies, Web-based Applications, cloud solutions and Databases.  Data warehouse: Data analysis, star/ snow flake schema data modeling and design  specific todata warehousing and business intelligence environment.  Database: Experience in database designing, scalability, back-up and recovery,  writing andoptimizing SQL code and Stored Procedures, creating functions, views,  triggers and indexes.   Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL  Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure  data lake analytics(U-SQL).  Big Data: Worked Azure data lake store/analytics for big data processing and Azure  data factoryto schedule U-SQL jobs. Designed and developed end to end big data  solution for data insights.     Willing to relocate: Anywhere  WORK EXPERIENCESoftware Engineer  Microsoft - Manchester, UK.  December 2015 to Present  1. Microsoft Rewards Live dashboards:  Description: - Microsoft rewards is loyalty program that rewards Users for  browsing and shopping online. Microsoft Rewards members can earn points when  searching with Bing, browsing with Microsoft Edge and making purchases at the  Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up  bonus points for taking daily quizzes and tours on the Microsoft rewards website.  Rewards live dashboards gives a live picture of usage world-wide and by markets  like US, Canada, Australia, new user registration count, top/bottom performing  rewards offers, orders stats and weekly trends of user activities, orders and new  user registrations. the PBI tiles gets refreshed in different frequencies starting  from 5 seconds to 30 minutes.  Technology/Tools used  Event hub, stream analytics and Power BI.  Responsibilities  Created stream analytics jobs to process event hub data  Created Power BI live dashboard to show live usage traffic, weekly trends, cards,  charts to showtop/bottom 10 offers and usage metrics.  2. Microsoft Rewards Data Insights:  Description: - Microsoft rewards is loyalty program that rewards Users for  browsing and shopping online. Microsoft Rewards members can earn points when  searching with Bing, browsing with Microsoft Edge and making purchases at the  Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up  bonus points for taking daily quizzes and tours on the Microsoft rewards website.  Rewards data insights is data analytics and reporting platform, processes 20  million users daily activities and redemption across different markets like US,  Canada, Australia.  Technology/Tools used  Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI.  Responsibilities  Created big data scripts in cosmos  C# data extractors, processors and reducers for data transformation  Power BI dashboards  3. End to end tracking Tool:  Description: - This is real-time Tracking tool to track different business  transactions like order, order response, functional acknowledgement, invoice  flowing inside ICOE. It gives flexibility to customers to track their transactions  and appropriate error information in-case of any failure. Based on resource based  access control the tool gives flexibility to end user to perform different actions  like view transactions, search based on different filter criteria and view and  download actual message payload. End to end tracking tool stitches all the  business transaction like order to cash flow and connects different hops inside  ICOE like gateway, routing server, Processing server. It also connects different  systems like ICOE, partner end point and SAP.  Technology/Tools used  Azure Document db, Azure web job and Web APP, RBAC, Angular JS.  Responsibilities  Document dB stored procedures.  Web job to process event hub data and populate Document db• Web App API.  Stream analytics job to transform data  Power BI reports  4. Biztrack Tracking Tool:  Description: - This is real-time Tracking tool to track different business  transactions like order, order response, functional acknowledgement, invoice  flowing inside ICOE. It gives flexibility to customers to track their transactions  and appropriate error information in-case of any failure. Based on resource based  access control the tool gives flexibility to end user to perform different actions  like view transactions, search based on different filter criteria and view and  download actual message payload.  Technology/Tools used  SQL server 2014, SSIS, .net API, Angular JS.  Responsibilities  ETL solution to transform business transactions data stored in Biztalk tables.  SQL azure tables, stored procedures, User defined functions.  Performance tuning.  Web API enhancements.    EDUCATION  The University of Manchester - UK  2007    SKILLS  problem solving (Less than 1 year), project lifecycle (Less than 1 year), project  manager (Less than 1 year), technical assistance. (Less than 1 year)  ADDITIONAL INFORMATION  Professional Skills  Excellent analytical, problem solving, communication, knowledge transfer and  interpersonalskills with ability to interact with individuals at all the levels  Quick learner and maintains cordial relationship with project manager and team  members andgood performer both in team and independent job environments  Positive attitude towards superiors &amp; peers  Supervised junior developers throughout project lifecycle and provided technical  assistance.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the model\n",
        "doc = nlp_model(art)\n",
        "list1=[]\n",
        "list2 = []\n",
        "for ent in doc.ents:\n",
        "    list1.append(ent.label_.upper())\n",
        "    list2.append(ent.text)\n",
        "dictionary = dict(zip(list1, list2))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUG27Ev6AkzA",
        "outputId": "f94f0743-970b-448e-d968-f1c5a3736ba4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'COMPANIES WORKED AT': 'Microsoft',\n",
              " 'EMAIL ADDRESS': 'indeed.com/r/falicent/140749dace5dc26f',\n",
              " 'NAME': 'Michael Smith',\n",
              " 'SKILLS': 'problem solving (Less than 1 year), project lifecycle (Less than 1 year), project'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "      \n",
        "# Serializing jsona  \n",
        "json_object = json.dumps(dictionary, indent = 4) \n",
        "print(json_object)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuffKdJGA7R3",
        "outputId": "76c5a6dd-4286-49e2-e1cb-0b676ed72ff1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"NAME\": \"Michael Smith\",\n",
            "    \"EMAIL ADDRESS\": \"indeed.com/r/falicent/140749dace5dc26f\",\n",
            "    \"COMPANIES WORKED AT\": \"Microsoft\",\n",
            "    \"SKILLS\": \"problem solving (Less than 1 year), project lifecycle (Less than 1 year), project\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}